<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tarefa 1 - Memória Cache e Row/Column Major</title>
    <style>
      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
        line-height: 1.6;
        color: #333;
      }

      h1 {
        color: #2c3e50;
        border-bottom: 3px solid #3498db;
        padding-bottom: 10px;
        margin-bottom: 30px;
      }

      h2 {
        color: #34495e;
        margin-top: 30px;
        margin-bottom: 15px;
        padding-left: 10px;
        border-left: 4px solid #3498db;
      }

      h3 {
        color: #2980b9;
        margin-top: 25px;
      }

      p {
        text-align: justify;
        margin-bottom: 15px;
      }

      .highlight {
        background-color: #f8f9fa;
        border-left: 4px solid #e74c3c;
        padding: 15px;
        margin: 20px 0;
        border-radius: 5px;
      }

      .analogy {
        background-color: #ebf3fd;
        border: 1px solid #3498db;
        padding: 15px;
        margin: 20px 0;
        border-radius: 8px;
      }

      .code-example {
        background-color: #f4f4f4;
        border: 1px solid #ddd;
        padding: 15px;
        margin: 15px 0;
        border-radius: 5px;
        font-family: "Courier New", monospace;
        overflow-x: auto;
      }

      ul {
        margin-left: 20px;
      }

      li {
        margin-bottom: 8px;
      }

      .footer {
        margin-top: 50px;
        padding-top: 20px;
        border-top: 1px solid #ddd;
        text-align: center;
        color: #666;
        font-size: 14px;
      }

      .performance-box {
        background-color: #d5edda;
        border: 1px solid #c3e6cb;
        padding: 15px;
        margin: 20px 0;
        border-radius: 8px;
      }

      @media print {
        body {
          max-width: none;
          margin: 0;
          padding: 15px;
        }

        .page-break {
          page-break-before: always;
        }
      }
    </style>
  </head>
  <body>
    <h1>
      Memória Cache, Localidade Espacial e Temporal, e Row Major vs Column Major
      em C
    </h1>

    <h2>Memória Cache: A Memória Rápida da CPU</h2>

    <p>
      A memória cache é uma memória de pequena capacidade, extremamente rápida e
      localizada fisicamente próxima ao processador, que armazena cópias de
      dados e instruções frequentemente acessados da memória principal (RAM).
      Sua existência é uma solução para o descompasso de velocidade entre a CPU,
      que é muito rápida, e a RAM, que é comparativamente lenta. Esse
      desequilíbrio é conhecido como <strong>"Gap de Velocidade"</strong> ou
      <strong>"Von Neumann Bottleneck"</strong>.
    </p>

    <p>
      A latência de acesso à memória cache L1 é tipicamente de 1-4 ciclos de clock,
      enquanto o acesso à RAM pode requerer 200-400 ciclos. Esta diferença substancial
      justifica a implementação de múltiplos níveis de cache para otimizar o desempenho
      do sistema através da redução do número médio de acessos à memória principal.
    </p>

    <p>
      A hierarquia de memória é organizada em níveis (L1, L2, L3), com a L1
      sendo a menor e mais rápida, localizada dentro do próprio núcleo do
      processador, e a L3 sendo maior e um pouco mais lenta, porém compartilhada
      entre vários núcleos. O princípio fundamental por trás da eficácia da
      cache é a <strong>localidade</strong>, que se divide em dois tipos:
      espacial e temporal.
    </p>

    <h2>Localidade Espacial e Temporal</h2>

    <h3>Localidade Temporal</h3>

    <p>
      A localidade temporal é um princípio fundamental que estabelece que
      <strong>dados acessados recentemente têm alta probabilidade de serem acessados 
      novamente em um intervalo de tempo próximo</strong>. Este comportamento é 
      explorado pelos algoritmos de substituição de cache, como LRU (Least Recently Used).
    </p>

    <p>
      Este princípio se manifesta principalmente em estruturas de controle como loops,
      onde variáveis de iteração, condições de parada e dados processados repetidamente
      são mantidos na cache. A eficácia da localidade temporal é quantificada pela
      taxa de cache hits em acessos subsequentes ao mesmo endereço de memória.
    </p>

    <p>
      Algoritmos que processam os mesmos dados múltiplas vezes (como operações em
      matrizes densas) beneficiam-se significativamente da localidade temporal,
      especialmente quando o working set de dados cabe nos níveis superiores da
      hierarquia de cache.
    </p>

    <div class="highlight">
      <p>
        <strong>Cache Hit vs Cache Miss:</strong> A cache age com base nesse
        princípio: quando um dado é buscado da memória principal, ele é copiado
        para a cache. Se esse mesmo dado for solicitado novamente e ainda
        estiver lá (um <em>acerto de cache</em>, ou cache hit), a CPU o obtém
        imediatamente. Se não estiver (uma <em>falha de cache</em>, ou cache
        miss), ocorre a custosa viagem à RAM.
      </p>
    </div>

    <h3>Localidade Espacial</h3>

    <p>
      A localidade espacial é um princípio que explora a proximidade física dos
      dados na memória. Este princípio estabelece que
      <strong>após acessar um endereço de memória, existe alta probabilidade 
      de acessos subsequentes a endereços adjacentes</strong>.
    </p>

    <p>
      A implementação prática deste princípio baseia-se na organização da memória
      e cache em <strong>linhas de cache</strong> (cache lines), blocos contíguos
      de dados tipicamente de 64 bytes em arquiteturas x86-64. Quando ocorre um
      cache miss, toda a linha de cache contendo o endereço solicitado é transferida
      da memória principal para a cache, não apenas o byte individual.
    </p>

    <p>
      Esta estratégia é altamente eficaz para padrões de acesso sequencial,
      como iteração sobre arrays, onde elementos adjacentes na memória são
      acessados consecutivamente. O resultado é uma alta taxa de cache hits
      para acessos subsequentes dentro da mesma linha de cache.
    </p>

    <div class="page-break"></div>

    <h2>Row Major vs Column Major em C</h2>

    <p>
      Em C, arrays multidimensionais são armazenados em
      <strong>row major order</strong>, ou seja, elementos de uma mesma linha
      estão em posições consecutivas na memória. Quando acessamos os elementos
      linha por linha, aproveitamos a localidade espacial, pois os dados já
      estão próximos na memória, tornando o acesso mais rápido devido ao cache.
    </p>

    <p>
      Já no <strong>column major order</strong> (usado em outras linguagens como
      Fortran e MATLAB), os elementos de uma mesma coluna estão próximos. Em C,
      acessar coluna por coluna resulta em saltos maiores na memória, reduzindo
      o aproveitamento da cache e tornando o acesso mais lento.
    </p>

    <h3>Layout de Memória em Row-Major</h3>

    <p>
      Em sistemas row-major, uma matriz bidimensional A[m][n] é mapeada linearmente
      na memória onde o elemento A[i][j] está localizado no endereço:
      <strong>base_address + (i × n + j) × sizeof(element)</strong>
    </p>

    <p>
      Esta organização implica que elementos consecutivos de uma linha (j, j+1, j+2...)
      estão em endereços de memória adjacentes, maximizando a eficiência da cache
      para acessos sequenciais por linha. Conversamente, elementos de uma coluna
      (A[i][j], A[i+1][j], A[i+2][j]...) estão separados por um stride de n×sizeof(element)
      bytes, potencialmente causando cache miss em cada acesso.
    </p>

    <div class="code-example">
      <strong>Exemplo em C (Row Major):</strong><br />
      int matriz[3][4] = {{1,2,3,4}, {5,6,7,8}, {9,10,11,12}};<br /><br />

      <strong>Memória:</strong>
      [1][2][3][4][5][6][7][8][9][10][11][12]<br /><br />

      <strong>Acesso eficiente (por linhas):</strong><br />
      for(i=0; i&lt;3; i++)<br />
      &nbsp;&nbsp;&nbsp;&nbsp;for(j=0; j&lt;4; j++)<br />
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;printf("%d ",
      matriz[i][j]); // Acesso sequencial<br /><br />

      <strong>Acesso ineficiente (por colunas):</strong><br />
      for(j=0; j&lt;4; j++)<br />
      &nbsp;&nbsp;&nbsp;&nbsp;for(i=0; i&lt;3; i++)<br />
      &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;printf("%d ",
      matriz[i][j]); // Saltos na memória
    </div>

    <div class="performance-box">
      <h3>Métricas de Performance</h3>
      <ul>
        <li>
          <strong>Row-major access:</strong> Taxa de cache miss ≈ 1/(elementos_por_cache_line)
        </li>
        <li>
          <strong>Column-major access:</strong> Taxa de cache miss ≈ 100% para matrizes grandes
        </li>
        <li>
          <strong>Bandwidth utilization:</strong> Row-major utiliza ~100% da bandwidth de memória, column-major ~1-10%
        </li>
        <li>
          <strong>Latência efetiva:</strong> Diferença pode alcançar 2-3 ordens de magnitude
        </li>
      </ul>
    </div>

    <div class="page-break"></div>

    <h2>Resultados Experimentais</h2>

    <p>
      Os resultados a seguir foram obtidos através da execução do programa de teste de multiplicação 
      matriz-vetor, comparando o desempenho entre acesso por linhas (row-major) e acesso por colunas 
      (column-major) em diferentes tamanhos de matriz.
    </p>

    <div class="code-example">
      <h3>Resultados dos Testes de Performance</h3>
      <pre>
=====================================================
           TESTE COM MATRIZ 200x200
=====================================================
Acesso por linhas   | 0.000194 s
Acesso por colunas  | 0.000194 s
Performance: colunas 1.00x (equivalente)

=====================================================
           TESTE COM MATRIZ 400x400
=====================================================
Acesso por linhas   | 0.000581 s
Acesso por colunas  | 0.000811 s
Performance: linhas 1.39x mais rápido

=====================================================
           TESTE COM MATRIZ 600x600
=====================================================
Acesso por linhas   | 0.001395 s
Acesso por colunas  | 0.002440 s
Performance: linhas 1.75x mais rápido

=====================================================
           TESTE COM MATRIZ 800x800
=====================================================
Acesso por linhas   | 0.003347 s
Acesso por colunas  | 0.004035 s
Performance: linhas 1.21x mais rápido

=====================================================
           TESTE COM MATRIZ 1000x1000
=====================================================
Acesso por linhas   | 0.004375 s
Acesso por colunas  | 0.007084 s
Performance: linhas 1.62x mais rápido

=====================================================
           TESTE COM MATRIZ 1500x1500
=====================================================
Acesso por linhas   | 0.009737 s
Acesso por colunas  | 0.017701 s
Performance: linhas 1.82x mais rápido

=====================================================
           TESTE COM MATRIZ 2000x2000
=====================================================
Acesso por linhas   | 0.014221 s
Acesso por colunas  | 0.035507 s
Performance: linhas 2.50x mais rápido

=====================================================
           TESTE COM MATRIZ 2500x2500
=====================================================
Acesso por linhas   | 0.022652 s
Acesso por colunas  | 0.060502 s
Performance: linhas 2.67x mais rápido

=====================================================
           TESTE COM MATRIZ 3000x3000
=====================================================
Acesso por linhas   | 0.031533 s
Acesso por colunas  | 0.088898 s
Performance: linhas 2.82x mais rápido

=====================================================
           TESTE COM MATRIZ 3500x3500
=====================================================
Acesso por linhas   | 0.043085 s
Acesso por colunas  | 0.128384 s
Performance: linhas 2.98x mais rápido

=====================================================
           TESTE COM MATRIZ 4000x4000
=====================================================
Acesso por linhas   | 0.055976 s
Acesso por colunas  | 0.182275 s
Performance: linhas 3.26x mais rápido

=====================================================
           TESTE COM MATRIZ 5000x5000
=====================================================
Acesso por linhas   | 0.087609 s
Acesso por colunas  | 0.282290 s
Performance: linhas 3.22x mais rápido
      </pre>
    </div>

    <div class="page-break"></div>

    <h2>Análise da Divergência Crítica de Performance</h2>

    <div class="highlight">
      <h3>Identificação do Ponto de Divergência Significativa</h3>
      <p>
        A análise detalhada dos resultados experimentais revela que <strong>2000×2000 (32 MB de working set)</strong> 
        representa o ponto crítico onde os tempos de execução passam a divergir significativamente entre os dois 
        padrões de acesso à memória. Este ponto marca uma transição fundamental no comportamento de performance.
      </p>
      
      <p>
        Observa-se um <strong>salto abrupto de 1.82x para 2.50x</strong> entre as matrizes 1500×1500 e 2000×2000, 
        indicando uma mudança qualitativa no regime de operação do sistema de memória.
      </p>
    </div>

    <div class="performance-box">
      <h3>Análise por Fases de Comportamento</h3>
      
      <h4>Fase 1: Matrizes Pequenas e Médias (≤ 1500×1500, ≤ 18 MB)</h4>
      <ul>
        <li><strong>Working Set:</strong> 320 KB - 18 MB (cabe parcial/totalmente na cache L3)</li>
        <li><strong>Speedup:</strong> 1.00x - 1.82x (inconsistente e moderado)</li>
        <li><strong>Característica:</strong> Competição por recursos de cache entre padrões</li>
        <li><strong>Comportamento:</strong> Diferenças mascaradas por cache hits ocasionais em ambos os padrões</li>
      </ul>

      <h4>Fase 2: Matrizes Grandes (≥ 2000×2000, ≥ 32 MB)</h4>
      <ul>
        <li><strong>Working Set:</strong> ≥ 32 MB (excede completamente cache L3 típica)</li>
        <li><strong>Speedup:</strong> 2.50x - 3.26x (alto e consistente)</li>
        <li><strong>Característica:</strong> Exposição completa da diferença fundamental entre padrões</li>
        <li><strong>Comportamento:</strong> Column-major causa cache thrashing, row-major mantém eficiência</li>
      </ul>
    </div>

    <div class="code-example">
      <h3>Análise Técnica da Causa da Divergência</h3>
      <pre>
<strong>Cálculo do Working Set Crítico:</strong>
Para matriz N×N com elementos double (8 bytes):
• 1500×1500: 1500² × 8 = 18 MB (ainda cabe parcialmente na L3)
• 2000×2000: 2000² × 8 = 32 MB ← <strong>Ponto crítico</strong>
• 5000×5000: 5000² × 8 = 200 MB (muito superior à L3)

<strong>Cache L3 Típica:</strong> 16-32 MB
<strong>Cache Line:</strong> 64 bytes (8 elementos double)

<strong>Padrões de Stride:</strong>
• Row-major: 8 bytes (acesso sequencial)
• Column-major (N=2000): 2000 × 8 = 16,000 bytes
  → 250x maior que cache line (64 bytes)

<strong>Miss Rate Estimado para Working Set > L3:</strong>
• Row-major: ~12.5% (1 miss a cada 8 acessos)
• Column-major: ~100% (miss em praticamente cada acesso)

<strong>Diferença de Latência:</strong>
• Cache L1/L2: ~4 ciclos de clock
• RAM: ~300 ciclos de clock
• Ratio teórico: 300/4 = 75x
• Ratio observado: ~3.2x (limitado por prefetching e paralelismo)
      </pre>
    </div>

    <div class="highlight">
      <h3>Explicação do Fenômeno de Divergência</h3>
      <p>A divergência significativa a partir de <strong>2000×2000</strong> ocorre devido a múltiplos fatores convergentes:</p>
      <ul>
        <li><strong>Excesso do Threshold de Cache L3:</strong> Working set de 32 MB excede capacidade típica da cache L3 (16-32 MB)</li>
        <li><strong>Cache Thrashing Completo:</strong> Column-major passa a causar cache miss em ~100% dos acessos</li>
        <li><strong>Manutenção da Eficiência Row-Major:</strong> Acesso sequencial continua aproveitando cache lines completas</li>
        <li><strong>Saturação de Bandwidth:</strong> Column-major satura bus de memória com transferências ineficientes</li>
        <li><strong>Dominância da Latência:</strong> Diferença entre cache (~4 ciclos) e RAM (~300 ciclos) se torna fator determinante</li>
      </ul>
    </div>

    <div class="footer">
      <p>
        Programação Paralela - Tarefa 1: Análise de Memória Cache e Padrões de
        Acesso
      </p>
      <p>
        Documento gerado automaticamente - Para conversão em PDF use: Ctrl+P →
        Salvar como PDF
      </p>
    </div>
  </body>
</html>
