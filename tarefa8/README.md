# Tarefa 8: Estimativa EstocÃ¡stica de Ï€ com OpenMP

## ğŸ“‹ DescriÃ§Ã£o do Problema

Este projeto implementa quatro versÃµes diferentes de estimativa estocÃ¡stica de Ï€ usando o mÃ©todo de Monte Carlo com paralelizaÃ§Ã£o OpenMP. O objetivo Ã© comparar diferentes estratÃ©gias de sincronizaÃ§Ã£o e geradores de nÃºmeros aleatÃ³rios.

## ğŸ¯ Objetivos

1. **Implementar estimativa de Ï€** usando mÃ©todo de Monte Carlo
2. **Comparar estratÃ©gias de sincronizaÃ§Ã£o**:
   - RegiÃ£o crÃ­tica (`#pragma omp critical`)
   - VetorizaÃ§Ã£o (cada thread escreve em posiÃ§Ã£o prÃ³pria)
3. **Comparar geradores de nÃºmeros aleatÃ³rios**:
   - `rand()` (nÃ£o thread-safe)
   - `rand_r()` (thread-safe)

## ğŸ§® Teoria: MÃ©todo de Monte Carlo para Ï€

### Fundamento MatemÃ¡tico

O mÃ©todo utiliza a relaÃ§Ã£o entre a Ã¡rea de um cÃ­rculo e um quadrado:

```
Ãrea do cÃ­rculo = Ï€ Ã— rÂ²
Ãrea do quadrado = (2r)Â²

RazÃ£o = Ï€ Ã— rÂ² / (2r)Â² = Ï€/4
```

### Algoritmo

1. Gerar pontos aleatÃ³rios (x,y) no intervalo [0,1]
2. Verificar se o ponto estÃ¡ dentro do cÃ­rculo: `xÂ² + yÂ² â‰¤ 1`
3. Contar quantos pontos estÃ£o dentro do cÃ­rculo
4. Estimar Ï€: `Ï€ â‰ˆ 4 Ã— (pontos_dentro / total_pontos)`

## ğŸ”§ ImplementaÃ§Ãµes

### VersÃ£o 1: `rand()` + RegiÃ£o CrÃ­tica
```c
#pragma omp parallel num_threads(nthreads)
{
    long long int acertos_priv = 0;
    #pragma omp for
    for (long long int i = 0; i < N; i++) {
        double x = (double)rand() / RAND_MAX;
        double y = (double)rand() / RAND_MAX;
        if (x*x + y*y <= 1.0) acertos_priv++;
    }
    #pragma omp critical
    acertos += acertos_priv;
}
```

**CaracterÃ­sticas:**
- âœ… Cada thread acumula em variÃ¡vel privada
- âœ… SincronizaÃ§Ã£o por regiÃ£o crÃ­tica
- âŒ `rand()` nÃ£o Ã© thread-safe
- âŒ PossÃ­vel contenÃ§Ã£o na regiÃ£o crÃ­tica

### VersÃ£o 2: `rand()` + Vetor Compartilhado
```c
#pragma omp parallel num_threads(nthreads)
{
    int tid = omp_get_thread_num();
    long long int acertos_priv = 0;
    #pragma omp for
    for (long long int i = 0; i < N; i++) {
        double x = (double)rand() / RAND_MAX;
        double y = (double)rand() / RAND_MAX;
        if (x*x + y*y <= 1.0) acertos_priv++;
    }
    acertos_vet[tid] = acertos_priv;
}
// Soma serial apÃ³s regiÃ£o paralela
for (int i = 0; i < nthreads; i++) acertos_total += acertos_vet[i];
```

**CaracterÃ­sticas:**
- âœ… Elimina contenÃ§Ã£o (cada thread escreve em posiÃ§Ã£o prÃ³pria)
- âœ… Soma serial apÃ³s paralelizaÃ§Ã£o
- âŒ `rand()` nÃ£o Ã© thread-safe
- âœ… Melhor escalabilidade

### VersÃ£o 3: `rand_r()` + RegiÃ£o CrÃ­tica
```c
#pragma omp parallel num_threads(nthreads)
{
    unsigned int seed = (unsigned int)time(NULL) ^ omp_get_thread_num();
    long long int acertos_priv = 0;
    #pragma omp for
    for (long long int i = 0; i < N; i++) {
        double x = (double)rand_r(&seed) / RAND_MAX;
        double y = (double)rand_r(&seed) / RAND_MAX;
        if (x*x + y*y <= 1.0) acertos_priv++;
    }
    #pragma omp critical
    acertos += acertos_priv;
}
```

**CaracterÃ­sticas:**
- âœ… `rand_r()` Ã© thread-safe
- âœ… Cada thread tem seu prÃ³prio seed
- âŒ PossÃ­vel contenÃ§Ã£o na regiÃ£o crÃ­tica
- âœ… GeraÃ§Ã£o de nÃºmeros aleatÃ³rios correta

### VersÃ£o 4: `rand_r()` + Vetor Compartilhado
```c
#pragma omp parallel num_threads(nthreads)
{
    int tid = omp_get_thread_num();
    unsigned int seed = (unsigned int)time(NULL) ^ tid;
    long long int acertos_priv = 0;
    #pragma omp for
    for (long long int i = 0; i < N; i++) {
        double x = (double)rand_r(&seed) / RAND_MAX;
        double y = (double)rand_r(&seed) / RAND_MAX;
        if (x*x + y*y <= 1.0) acertos_priv++;
    }
    acertos_vet[tid] = acertos_priv;
}
```

**CaracterÃ­sticas:**
- âœ… `rand_r()` Ã© thread-safe
- âœ… Elimina contenÃ§Ã£o
- âœ… Melhor escalabilidade
- âœ… ImplementaÃ§Ã£o mais robusta

## ğŸ“Š Resultados Experimentais

### ConfiguraÃ§Ã£o do Teste
- **Pontos:** 100.000.000
- **Threads:** 4
- **Compilador:** GCC com `-fopenmp`

### Tempos de ExecuÃ§Ã£o

| VersÃ£o | Gerador | SincronizaÃ§Ã£o | Tempo (s) | Ï€ Estimado | Speedup |
|--------|---------|---------------|-----------|------------|---------|
| 1 | `rand()` | Critical | ~18.0 | 3.1416653 | 1.0x |
| 2 | `rand()` | Vetor | ~17.4 | 3.1413922 | 1.03x |
| 3 | `rand_r()` | Critical | ~0.48 | 3.1416518 | 37.5x |
| 4 | `rand_r()` | Vetor | ~0.44 | 3.1416518 | 40.9x |

### AnÃ¡lise dos Resultados

#### ğŸš€ Performance DramÃ¡tica com `rand_r()`
- **37-40x speedup** ao trocar `rand()` por `rand_r()`
- DiferenÃ§a nÃ£o Ã© apenas thread-safety, mas contenÃ§Ã£o interna

#### ğŸ”’ Impacto da SincronizaÃ§Ã£o
- DiferenÃ§a pequena entre critical e vetor (~8% melhoria)
- Vetor compartilhado tem vantagem em escalabilidade

#### ğŸ² Thread-Safety dos Geradores
- `rand()`: Usa estado global compartilhado â†’ contenÃ§Ã£o severa
- `rand_r()`: Estado local por thread â†’ paralelismo real

## ğŸ’¡ ConclusÃµes

### LiÃ§Ãµes Aprendidas

1. **Thread-Safety Ã© Crucial**: A diferenÃ§a entre `rand()` e `rand_r()` domina completamente a performance
2. **ContenÃ§Ã£o Interna**: `rand()` tem mutex interno que serializa execuÃ§Ã£o
3. **EstratÃ©gia de SincronizaÃ§Ã£o**: Vetor compartilhado Ã© ligeiramente melhor que regiÃ£o crÃ­tica
4. **Escalabilidade**: VersÃ£o 4 (`rand_r()` + vetor) Ã© a mais escalÃ¡vel

### RecomendaÃ§Ãµes

- **Use sempre `rand_r()`** em cÃ³digo paralelo
- **Prefira vetorizaÃ§Ã£o** para reduzir contenÃ§Ã£o
- **Inicialize seeds Ãºnicos** por thread
- **MeÃ§a performance** de diferentes estratÃ©gias

## ğŸ”¨ Como Compilar e Executar

```bash
# Compilar
gcc -fopenmp tarefa8.c -o tarefa8

# Executar com padrÃµes (100M pontos, 4 threads)
./tarefa8

# Executar com parÃ¢metros customizados
./tarefa8 <numero_pontos> <numero_threads>

# Exemplo: 50M pontos, 8 threads
./tarefa8 50000000 8
```

## ğŸ“š Conceitos Importantes

### OpenMP
- **`#pragma omp parallel`**: Cria regiÃ£o paralela
- **`#pragma omp for`**: Distribui iteraÃ§Ãµes entre threads
- **`#pragma omp critical`**: SeÃ§Ã£o crÃ­tica (acesso exclusivo)
- **`omp_get_thread_num()`**: ID da thread atual

### Thread-Safety
- **Thread-safe**: FunÃ§Ã£o pode ser chamada simultaneamente por mÃºltiplas threads
- **Race condition**: Resultado depende da ordem de execuÃ§Ã£o das threads
- **ContenÃ§Ã£o**: Threads competem por mesmo recurso

### EstratÃ©gias de ReduÃ§Ã£o
- **Critical section**: Serializa acesso a variÃ¡vel compartilhada
- **Private accumulation**: Cada thread acumula localmente, depois combina
- **Array indexing**: Cada thread escreve em posiÃ§Ã£o Ãºnica

## ğŸ“ ExercÃ­cios Propostos

1. Teste com diferentes nÃºmeros de threads (1, 2, 4, 8, 16)
2. Compare com `reduction(+:acertos)` do OpenMP
3. Implemente versÃ£o com `drand48_r()`
4. Analise cache misses com ferramentas de profiling
5. Teste em diferentes arquiteturas (ARM, x86)

---
*Este projeto demonstra conceitos fundamentais de programaÃ§Ã£o paralela, thread-safety e otimizaÃ§Ã£o de performance em aplicaÃ§Ãµes cientÃ­ficas.*
