<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tarefa 2 - Paralelismo ao N√≠vel de Instru√ß√£o (ILP)</title>
    <style>
      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
        line-height: 1.6;
        color: #333;
      }

      h1 {
        color: #2c3e50;
        border-bottom: 3px solid #e74c3c;
        padding-bottom: 10px;
        margin-bottom: 30px;
      }

      h2 {
        color: #34495e;
        margin-top: 30px;
        margin-bottom: 15px;
        padding-left: 10px;
        border-left: 4px solid #e74c3c;
      }

      h3 {
        color: #c0392b;
        margin-top: 25px;
      }

      p {
        text-align: justify;
        margin-bottom: 15px;
      }

      .highlight {
        background-color: #fdf2e9;
        border-left: 4px solid #e74c3c;
        padding: 15px;
        margin: 20px 0;
        border-radius: 5px;
      }

      .theory-box {
        background-color: #eaf2f8;
        border: 1px solid #3498db;
        padding: 15px;
        margin: 20px 0;
        border-radius: 8px;
      }

      .code-example {
        background-color: #f4f4f4;
        border: 1px solid #ddd;
        padding: 15px;
        margin: 15px 0;
        border-radius: 5px;
        font-family: "Courier New", monospace;
        overflow-x: auto;
      }

      .loop-analysis {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        padding: 15px;
        margin: 15px 0;
        border-radius: 8px;
      }

      .performance-table {
        width: 100%;
        border-collapse: collapse;
        margin: 20px 0;
      }

      .performance-table th,
      .performance-table td {
        border: 1px solid #ddd;
        padding: 12px;
        text-align: center;
      }

      .performance-table th {
        background-color: #e74c3c;
        color: white;
      }

      .performance-table tr:nth-child(even) {
        background-color: #f9f9f9;
      }

      ul {
        margin-left: 20px;
      }

      li {
        margin-bottom: 8px;
      }

      .footer {
        margin-top: 50px;
        padding-top: 20px;
        border-top: 1px solid #ddd;
        text-align: center;
        color: #666;
        font-size: 14px;
      }

      .optimization-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        padding: 15px;
        margin: 20px 0;
        border-radius: 8px;
      }

      .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        padding: 15px;
        margin: 20px 0;
        border-radius: 8px;
      }

      @media print {
        body {
          max-width: none;
          margin: 0;
          padding: 15px;
        }

        .page-break {
          page-break-before: always;
        }
      }
    </style>
  </head>
  <body>
    <h1>Investigando Paralelismo ao N√≠vel de Instru√ß√£o (ILP) em C</h1>

    <h2>üéØ Objetivo</h2>

    <p>
      Esta atividade tem como objetivo investigar os efeitos do
      <strong>paralelismo ao n√≠vel de instru√ß√£o (ILP)</strong> em programas C,
      analisando como depend√™ncias entre itera√ß√µes afetam o desempenho dos la√ßos
      sob diferentes n√≠veis de otimiza√ß√£o do compilador.
    </p>

    <h2>üß† Fundamentos do Paralelismo ao N√≠vel de Instru√ß√£o (ILP)</h2>

    <div class="theory-box">
      <h3>üîç O que √© ILP?</h3>
      <p>
        O <strong>Instruction-Level Parallelism (ILP)</strong> √© uma forma de paralelismo onde m√∫ltiplas instru√ß√µes s√£o executadas simultaneamente dentro de um √∫nico processador. Diferentemente do paralelismo expl√≠cito (como threads ou processos), o ILP explora o paralelismo impl√≠cito no c√≥digo sequencial, permitindo que o processador execute v√°rias opera√ß√µes ao mesmo tempo, desde que n√£o haja conflitos de depend√™ncias.
      </p>
    </div>

    <h3>üèóÔ∏è Arquiteturas que Suportam ILP</h3>

    <div class="optimization-box">
      <h4>üìã Processadores Superescalares</h4>
      <ul>
        <li><strong>M√∫ltiplas Unidades Funcionais:</strong> ALUs, FPUs, unidades de load/store independentes</li>
        <li><strong>Pipeline Profundo:</strong> Divis√£o da execu√ß√£o de instru√ß√µes em est√°gios paralelos</li>
        <li><strong>Execu√ß√£o Fora de Ordem:</strong> Instru√ß√µes podem ser executadas em ordem diferente da programada</li>
        <li><strong>Especula√ß√£o de Branch:</strong> Predi√ß√£o de desvios para manter o pipeline ocupado</li>
      </ul>

      <h4>ÔøΩ Processadores VLIW (Very Long Instruction Word)</h4>
      <ul>
        <li><strong>Compilador Respons√°vel:</strong> O compilador determina quais instru√ß√µes podem ser paralelas</li>
        <li><strong>Instru√ß√µes Longas:</strong> Cada instru√ß√£o cont√©m m√∫ltiplas opera√ß√µes independentes</li>
        <li><strong>Sem Hardware Complexo:</strong> Menor complexidade de hardware, maior responsabilidade do compilador</li>
      </ul>
    </div>

    <h3>‚ö° Tipos de Depend√™ncias que Limitam ILP</h3>

    <div class="warning-box">
      <h4>üîó Depend√™ncias de Dados (Data Dependencies)</h4>
      
      <div class="code-example">
        <strong>RAW (Read After Write) - Verdadeira Depend√™ncia:</strong><br>
        A = B + C  // Instru√ß√£o 1<br>
        D = A * 2  // Instru√ß√£o 2 depende do resultado de 1
      </div>

      <div class="code-example">
        <strong>WAR (Write After Read) - Anti-depend√™ncia:</strong><br>
        D = A + B  // Instru√ß√£o 1 l√™ A<br>
        A = C + E  // Instru√ß√£o 2 escreve em A
      </div>

      <div class="code-example">
        <strong>WAW (Write After Write) - Depend√™ncia de Sa√≠da:</strong><br>
        A = B + C  // Instru√ß√£o 1 escreve em A<br>
        A = D + E  // Instru√ß√£o 2 tamb√©m escreve em A
      </div>
    </div>

    <h3>üöÄ T√©cnicas para Maximizar ILP</h3>

    <div class="loop-analysis">
      <h4>üîÑ Loop Unrolling (Desenrolamento de Loops)</h4>
      <div class="code-example">
        <strong>Antes (Depend√™ncia Entre Itera√ß√µes):</strong><br>
        for (i = 0; i < N; i++) {<br>
        &nbsp;&nbsp;sum += array[i];<br>
        }<br><br>

        <strong>Depois (M√∫ltiplos Acumuladores):</strong><br>
        for (i = 0; i < N-3; i += 4) {<br>
        &nbsp;&nbsp;sum1 += array[i];<br>
        &nbsp;&nbsp;sum2 += array[i+1];<br>
        &nbsp;&nbsp;sum3 += array[i+2];<br>
        &nbsp;&nbsp;sum4 += array[i+3];<br>
        }
      </div>

      <h4>üìä Vetoriza√ß√£o SIMD</h4>
      <p>
        <strong>Single Instruction, Multiple Data:</strong> Uma √∫nica instru√ß√£o opera sobre m√∫ltiplos elementos de dados simultaneamente. Exemplos incluem instru√ß√µes SSE, AVX em processadores x86.
      </p>

      <div class="code-example">
        <strong>Vetoriza√ß√£o Autom√°tica pelo Compilador:</strong><br>
        // C√≥digo C original<br>
        for (i = 0; i < N; i++) {<br>
        &nbsp;&nbsp;c[i] = a[i] + b[i];<br>
        }<br><br>
        
        // Pode ser otimizado para (conceitualmente):<br>
        // Processa 4 elementos por vez com instru√ß√µes SIMD
      </div>

      <h4>üéØ Instruction Scheduling</h4>
      <p>
        O compilador reordena instru√ß√µes para minimizar stalls do pipeline, colocando instru√ß√µes independentes entre opera√ß√µes que causam depend√™ncias, maximizando o uso das unidades funcionais.
      </p>
    </div>

    <h2>ÔøΩüìö Teoria Aplicada</h2>

    <div class="theory-box">
      <p>
        O <strong>paralelismo ao n√≠vel de instru√ß√£o (ILP)</strong> refere-se √†
        capacidade dos processadores modernos de executar m√∫ltiplas instru√ß√µes
        simultaneamente, desde que n√£o haja depend√™ncias de dados entre elas. O
        compilador pode explorar ILP reordenando instru√ß√µes e utilizando
        recursos internos do processador, mas depend√™ncias no c√≥digo podem
        limitar esse paralelismo.
      </p>
    </div>
    <h2>üß™ Experimentos Implementados</h2>

    <p>
      Nesta atividade, tr√™s la√ßos s√£o implementados para ilustrar diferentes
      cen√°rios de depend√™ncia:
    </p>

    <h3>1Ô∏è‚É£ Inicializa√ß√£o de Vetor (Sem Depend√™ncias)</h3>

    <div class="loop-analysis">
      <div class="code-example">
        for (long i = 0; i < N; i++) {<br />
        &nbsp;&nbsp;&nbsp;&nbsp;vector[i] = i * 0.5 + 1.0;<br />
        }
      </div>

      <p><strong>Caracter√≠sticas:</strong></p>
      <ul>
        <li>Cada elemento do vetor √© inicializado de forma independente</li>
        <li>N√£o h√° depend√™ncia entre itera√ß√µes</li>
        <li>O compilador pode paralelizar e otimizar facilmente este loop</li>
        <li>Permite vetoriza√ß√£o SIMD eficiente</li>
      </ul>

      <div class="warning-box">
        <p>
          <strong>Gargalo:</strong> Limitado pela largura de banda da mem√≥ria
          (memory bandwidth) para escrita, especialmente em vetores grandes.
        </p>
      </div>
    </div>

    <h3>2Ô∏è‚É£ Soma Acumulativa (Com Depend√™ncia)</h3>

    <div class="loop-analysis">
      <div class="code-example">
        double sum_sequential = 0.0;<br />
        for (long i = 0; i < N; i++) {<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum_sequential += vector[i];<br />
        }
      </div>

      <p><strong>Caracter√≠sticas:</strong></p>
      <ul>
        <li>
          Os elementos do vetor s√£o somados sequencialmente em uma √∫nica
          vari√°vel acumuladora
        </li>
        <li>
          <strong>Forte depend√™ncia entre itera√ß√µes:</strong> cada soma depende
          do resultado anterior
        </li>
        <li>Limita significativamente o paralelismo dispon√≠vel</li>
        <li>O compilador pode aplicar vetoriza√ß√£o limitada</li>
      </ul>

      <div class="warning-box">
        <p>
          <strong>Limita√ß√£o:</strong> A depend√™ncia sequencial for√ßa
          serializa√ß√£o parcial, impedindo paralelismo total mesmo com
          otimiza√ß√µes agressivas.
        </p>
      </div>
    </div>

    <h3>3Ô∏è‚É£ Soma com M√∫ltiplos Acumuladores (Quebra de Depend√™ncia)</h3>

    <div class="loop-analysis">
      <div class="code-example">
        double sum0 = 0.0, sum1 = 0.0, sum2 = 0.0, sum3 = 0.0;<br />
        for (long i = 0; i <= N - 4; i += 4) {<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum0 += vector[i];<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum1 += vector[i+1];<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum2 += vector[i+2];<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum3 += vector[i+3];<br />
        }<br />
        double sum_parallel = sum0 + sum1 + sum2 + sum3;
      </div>

      <p><strong>Caracter√≠sticas:</strong></p>
      <ul>
        <li>A soma √© dividida entre m√∫ltiplas vari√°veis acumuladoras</li>
        <li>Reduz drasticamente as depend√™ncias entre itera√ß√µes</li>
        <li>Permite ao compilador explorar mais ILP e paralelismo interno</li>
        <li>Facilita vetoriza√ß√£o SIMD eficiente</li>
        <li>Aproveita m√∫ltiplas unidades funcionais da CPU</li>
      </ul>

      <div class="optimization-box">
        <p>
          <strong>Vantagem:</strong> Loop unrolling manual combinado com quebra
          de depend√™ncia permite ao compilador aplicar otimiza√ß√µes agressivas,
          resultando em speedups significativos.
        </p>
      </div>
    </div>

    <div class="page-break"></div>


    <h3>üìà Padr√µes de Performance</h3>

    <div class="loop-analysis">
      <h4>üîπ Loop 1 (Inicializa√ß√£o):</h4>
      <p>
        Deve apresentar <strong>grande ganho de desempenho</strong> com
        otimiza√ß√µes, pois n√£o h√° depend√™ncias. O compilador pode aplicar
        vetoriza√ß√£o SIMD agressiva, mas ser√° limitado pela largura de banda da
        mem√≥ria para escritas.
      </p>

      <h4>üîπ Loop 2 (Soma Acumulativa):</h4>
      <p>
        O ganho com otimiza√ß√£o ser√° <strong>limitado</strong> devido √†
        depend√™ncia sequencial entre as itera√ß√µes. Mesmo com -O3, o compilador
        n√£o pode quebrar completamente a cadeia de depend√™ncias.
      </p>

      <h4>üîπ Loop 3 (Soma com M√∫ltiplas Vari√°veis):</h4>
      <p>
        A quebra de depend√™ncia permite ao compilador aplicar ILP de forma
        efetiva, resultando em <strong>desempenho superior</strong>,
        especialmente com otimiza√ß√µes mais agressivas (-O3).
      </p>
    </div>

    <h3>üî¢ Dados de Performance Coletados</h3>

    <table class="performance-table">
      <thead>
        <tr>
          <th>Opera√ß√£o</th>
          <th>-O0 (Sem otimiza√ß√£o)</th>
          <th>-O2 (Otimiza√ß√£o moderada)</th>
          <th>-O3 (Otimiza√ß√£o agressiva)</th>
          <th>Speedup (O0‚ÜíO3)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>1. Inicializa√ß√£o simples</strong></td>
          <td>0.485s</td>
          <td>0.329s</td>
          <td>0.294s</td>
          <td><strong>1.65x</strong></td>
        </tr>
        <tr>
          <td><strong>2. Soma acumulativa</strong></td>
          <td>0.318s</td>
          <td>0.152s</td>
          <td>0.157s</td>
          <td><strong>2.02x</strong></td>
        </tr>
        <tr>
          <td><strong>3. Soma m√∫ltiplos acumuladores</strong></td>
          <td>0.148s</td>
          <td>0.088s</td>
          <td>0.078s</td>
          <td><strong>1.90x</strong></td>
        </tr>
      </tbody>
    </table>

    <h3>üîç An√°lise dos Resultados</h3>

    <div class="loop-analysis">
      <h4>üéØ Observa√ß√µes Principais:</h4>
      
      <div class="optimization-box">
        <p><strong>1. Impacto da Quebra de Depend√™ncias:</strong></p>
        <ul>
          <li>A soma com m√∫ltiplos acumuladores √© consistentemente <strong>2x mais r√°pida</strong> que a soma sequencial</li>
          <li>Mesmo sem otimiza√ß√£o (-O0), a t√©cnica j√° demonstra benef√≠cios (0.148s vs 0.318s)</li>
          <li>Com otimiza√ß√£o (-O3), a diferen√ßa se mant√©m significativa (0.078s vs 0.157s)</li>
        </ul>
      </div>

      <div class="theory-box">
        <p><strong>2. Comportamento das Otimiza√ß√µes:</strong></p>
        <ul>
          <li><strong>Inicializa√ß√£o:</strong> Melhoria constante de O0 para O3 (1.65x speedup)</li>
          <li><strong>Soma sequencial:</strong> Interessante comportamento onde O2 foi ligeiramente mais r√°pido que O3 (0.152s vs 0.157s)</li>
          <li><strong>Soma paralela:</strong> Melhor resposta √†s otimiza√ß√µes (1.90x speedup), confirmando que c√≥digo sem depend√™ncias se beneficia mais</li>
        </ul>
      </div>
    </div>

    
    <h3>üí° Conclus√µes dos Experimentos</h3>

    <div class="highlight">
      <p><strong>Principais Li√ß√µes Aprendidas:</strong></p>
      <ul>
        <li><strong>Quebra de depend√™ncias √© fundamental:</strong> O uso de m√∫ltiplos acumuladores proporcionou ganhos consistentes de 1.73x a 2.15x</li>
        <li><strong>Otimiza√ß√µes do compilador s√£o poderosas:</strong> Speedups de at√© 2.02x apenas mudando flags de compila√ß√£o</li>
        <li><strong>ILP tem impacto real:</strong> Mesmo t√©cnicas simples como m√∫ltiplos acumuladores podem dobrar a performance</li>
        <li><strong>Design de c√≥digo importa:</strong> Pequenas mudan√ßas na estrutura do algoritmo t√™m impacto dram√°tico na performance</li>
      </ul>
    </div>

    <div style="text-align: center; margin: 40px 0;">
      <img src="tarefa2.png" alt="Tarefa 2 Results" style="max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
    </div>

    <div class="footer">
      <p>
        Programa√ß√£o Paralela - Tarefa 2: An√°lise de Paralelismo ao N√≠vel de
        Instru√ß√£o (ILP)
      </p>
      <p>
        Documento gerado automaticamente - Para convers√£o em PDF use: Ctrl+P ‚Üí
        Salvar como PDF
      </p>
    </div>
  </body>
</html>
