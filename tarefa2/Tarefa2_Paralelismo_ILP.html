<!DOCTYPE html>
<html lang="pt-BR">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tarefa 2 - Paralelismo ao N√≠vel de Instru√ß√£o (ILP)</title>
    <style>
      body {
        font-family: "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
        max-width: 800px;
        margin: 0 auto;
        padding: 20px;
        line-height: 1.6;
        color: #333;
      }

      h1 {
        color: #2c3e50;
        border-bottom: 3px solid #e74c3c;
        padding-bottom: 10px;
        margin-bottom: 30px;
      }

      h2 {
        color: #34495e;
        margin-top: 30px;
        margin-bottom: 15px;
        padding-left: 10px;
        border-left: 4px solid #e74c3c;
      }

      h3 {
        color: #c0392b;
        margin-top: 25px;
      }

      p {
        text-align: justify;
        margin-bottom: 15px;
      }

      .highlight {
        background-color: #fdf2e9;
        border-left: 4px solid #e74c3c;
        padding: 15px;
        margin: 20px 0;
        border-radius: 5px;
      }

      .theory-box {
        background-color: #eaf2f8;
        border: 1px solid #3498db;
        padding: 15px;
        margin: 20px 0;
        border-radius: 8px;
      }

      .code-example {
        background-color: #f4f4f4;
        border: 1px solid #ddd;
        padding: 15px;
        margin: 15px 0;
        border-radius: 5px;
        font-family: "Courier New", monospace;
        overflow-x: auto;
      }

      .loop-analysis {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        padding: 15px;
        margin: 15px 0;
        border-radius: 8px;
      }

      .performance-table {
        width: 100%;
        border-collapse: collapse;
        margin: 20px 0;
      }

      .performance-table th,
      .performance-table td {
        border: 1px solid #ddd;
        padding: 12px;
        text-align: center;
      }

      .performance-table th {
        background-color: #e74c3c;
        color: white;
      }

      .performance-table tr:nth-child(even) {
        background-color: #f9f9f9;
      }

      ul {
        margin-left: 20px;
      }

      li {
        margin-bottom: 8px;
      }

      .footer {
        margin-top: 50px;
        padding-top: 20px;
        border-top: 1px solid #ddd;
        text-align: center;
        color: #666;
        font-size: 14px;
      }

      .optimization-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        padding: 15px;
        margin: 20px 0;
        border-radius: 8px;
      }

      .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        padding: 15px;
        margin: 20px 0;
        border-radius: 8px;
      }

      @media print {
        body {
          max-width: none;
          margin: 0;
          padding: 15px;
        }

        .page-break {
          page-break-before: always;
        }
      }
    </style>
  </head>
  <body>
    <h1>Investigando Paralelismo ao N√≠vel de Instru√ß√£o (ILP) em C</h1>

    <h2>üéØ Objetivo</h2>

    <p>
      Esta atividade tem como objetivo investigar os efeitos do
      <strong>paralelismo ao n√≠vel de instru√ß√£o (ILP)</strong> em programas C,
      analisando como depend√™ncias entre itera√ß√µes afetam o desempenho dos la√ßos
      sob diferentes n√≠veis de otimiza√ß√£o do compilador.
    </p>

    <div class="highlight">
      <p>
        <strong>Meta principal:</strong> Compreender como o compilador explora
        paralelismo interno e como depend√™ncias de dados podem limitar ou
        facilitar essas otimiza√ß√µes, especialmente em opera√ß√µes vetoriais e
        loops computacionalmente intensivos.
      </p>
    </div>

    <h2>üìö Teoria</h2>

    <div class="theory-box">
      <p>
        O <strong>paralelismo ao n√≠vel de instru√ß√£o (ILP)</strong> refere-se √†
        capacidade dos processadores modernos de executar m√∫ltiplas instru√ß√µes
        simultaneamente, desde que n√£o haja depend√™ncias de dados entre elas. O
        compilador pode explorar ILP reordenando instru√ß√µes e utilizando
        recursos internos do processador, mas depend√™ncias no c√≥digo podem
        limitar esse paralelismo.
      </p>
    </div>

    <h3>üîó Tipos de Depend√™ncia</h3>

    <ul>
      <li>
        <strong>Depend√™ncia de dados (RAW - Read After Write):</strong> Uma
        instru√ß√£o precisa do resultado de outra anterior
      </li>
      <li>
        <strong>Depend√™ncia anti (WAR - Write After Read):</strong> Uma
        instru√ß√£o escreve em um local que ser√° lido por outra
      </li>
      <li>
        <strong>Depend√™ncia de sa√≠da (WAW - Write After Write):</strong> Duas
        instru√ß√µes escrevem no mesmo local
      </li>
    </ul>

    <h3>üõ†Ô∏è T√©cnicas de Otimiza√ß√£o do Compilador</h3>

    <div class="optimization-box">
      <ul>
        <li>
          <strong>Vetoriza√ß√£o SIMD:</strong> Uso de instru√ß√µes que processam
          m√∫ltiplos dados simultaneamente
        </li>
        <li>
          <strong>Loop Unrolling:</strong> Desenrolar loops para reduzir
          overhead de controle
        </li>
        <li>
          <strong>Instruction Scheduling:</strong> Reordena√ß√£o de instru√ß√µes
          para maximizar paralelismo
        </li>
        <li>
          <strong>Register Allocation:</strong> Otimiza√ß√£o do uso de
          registradores
        </li>
      </ul>
    </div>

    <h2>üß™ Experimentos Implementados</h2>

    <p>
      Nesta atividade, tr√™s la√ßos s√£o implementados para ilustrar diferentes
      cen√°rios de depend√™ncia:
    </p>

    <h3>1Ô∏è‚É£ Inicializa√ß√£o de Vetor (Sem Depend√™ncias)</h3>

    <div class="loop-analysis">
      <div class="code-example">
        for (long i = 0; i < N; i++) {<br />
        &nbsp;&nbsp;&nbsp;&nbsp;vector[i] = i * 0.5 + 1.0;<br />
        }
      </div>

      <p><strong>Caracter√≠sticas:</strong></p>
      <ul>
        <li>Cada elemento do vetor √© inicializado de forma independente</li>
        <li>N√£o h√° depend√™ncia entre itera√ß√µes</li>
        <li>O compilador pode paralelizar e otimizar facilmente este loop</li>
        <li>Permite vetoriza√ß√£o SIMD eficiente</li>
      </ul>

      <div class="warning-box">
        <p>
          <strong>Gargalo:</strong> Limitado pela largura de banda da mem√≥ria
          (memory bandwidth) para escrita, especialmente em vetores grandes.
        </p>
      </div>
    </div>

    <h3>2Ô∏è‚É£ Soma Acumulativa (Com Depend√™ncia)</h3>

    <div class="loop-analysis">
      <div class="code-example">
        double sum_sequential = 0.0;<br />
        for (long i = 0; i < N; i++) {<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum_sequential += vector[i];<br />
        }
      </div>

      <p><strong>Caracter√≠sticas:</strong></p>
      <ul>
        <li>
          Os elementos do vetor s√£o somados sequencialmente em uma √∫nica
          vari√°vel acumuladora
        </li>
        <li>
          <strong>Forte depend√™ncia entre itera√ß√µes:</strong> cada soma depende
          do resultado anterior
        </li>
        <li>Limita significativamente o paralelismo dispon√≠vel</li>
        <li>O compilador pode aplicar vetoriza√ß√£o limitada</li>
      </ul>

      <div class="warning-box">
        <p>
          <strong>Limita√ß√£o:</strong> A depend√™ncia sequencial for√ßa
          serializa√ß√£o parcial, impedindo paralelismo total mesmo com
          otimiza√ß√µes agressivas.
        </p>
      </div>
    </div>

    <h3>3Ô∏è‚É£ Soma com M√∫ltiplos Acumuladores (Quebra de Depend√™ncia)</h3>

    <div class="loop-analysis">
      <div class="code-example">
        double sum0 = 0.0, sum1 = 0.0, sum2 = 0.0, sum3 = 0.0;<br />
        for (long i = 0; i <= N - 4; i += 4) {<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum0 += vector[i];<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum1 += vector[i+1];<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum2 += vector[i+2];<br />
        &nbsp;&nbsp;&nbsp;&nbsp;sum3 += vector[i+3];<br />
        }<br />
        double sum_parallel = sum0 + sum1 + sum2 + sum3;
      </div>

      <p><strong>Caracter√≠sticas:</strong></p>
      <ul>
        <li>A soma √© dividida entre m√∫ltiplas vari√°veis acumuladoras</li>
        <li>Reduz drasticamente as depend√™ncias entre itera√ß√µes</li>
        <li>Permite ao compilador explorar mais ILP e paralelismo interno</li>
        <li>Facilita vetoriza√ß√£o SIMD eficiente</li>
        <li>Aproveita m√∫ltiplas unidades funcionais da CPU</li>
      </ul>

      <div class="optimization-box">
        <p>
          <strong>Vantagem:</strong> Loop unrolling manual combinado com quebra
          de depend√™ncia permite ao compilador aplicar otimiza√ß√µes agressivas,
          resultando em speedups significativos.
        </p>
      </div>
    </div>

    <div class="page-break"></div>

    <h2>üî¨ Procedimento Experimental</h2>

    <ol>
      <li>
        <strong>Implementar os tr√™s loops em C</strong> conforme descrito acima
      </li>
      <li>
        <strong
          >Compilar o programa com diferentes n√≠veis de otimiza√ß√£o:</strong
        >
        <ul>
          <li><code>-O0</code>: Sem otimiza√ß√µes (baseline)</li>
          <li><code>-O2</code>: Otimiza√ß√µes moderadas</li>
          <li>
            <code>-O3</code>: Otimiza√ß√µes agressivas, incluindo vetoriza√ß√£o e
            paralelismo
          </li>
        </ul>
      </li>
      <li>
        <strong>Medir e comparar os tempos de execu√ß√£o</strong> de cada loop em
        cada n√≠vel de otimiza√ß√£o
      </li>
      <li>
        <strong>Analisar os resultados</strong> e identificar padr√µes de
        performance
      </li>
    </ol>

    <h2>üìä An√°lise de Resultados Esperados</h2>

    <table class="performance-table">
      <thead>
        <tr>
          <th>Loop</th>
          <th>-O0 (Baseline)</th>
          <th>-O2 (Moderado)</th>
          <th>-O3 (Agressivo)</th>
          <th>Speedup Esperado</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><strong>1. Inicializa√ß√£o</strong></td>
          <td>Lento</td>
          <td>R√°pido</td>
          <td>Muito R√°pido</td>
          <td>Alto (5-10x)</td>
        </tr>
        <tr>
          <td><strong>2. Soma Simples</strong></td>
          <td>Lento</td>
          <td>M√©dio</td>
          <td>R√°pido</td>
          <td>Moderado (2-4x)</td>
        </tr>
        <tr>
          <td><strong>3. Soma M√∫ltipla</strong></td>
          <td>Lento</td>
          <td>R√°pido</td>
          <td>Muito R√°pido</td>
          <td>Muito Alto (8-15x)</td>
        </tr>
      </tbody>
    </table>

    <h3>üìà Padr√µes de Performance</h3>

    <div class="loop-analysis">
      <h4>üîπ Loop 1 (Inicializa√ß√£o):</h4>
      <p>
        Deve apresentar <strong>grande ganho de desempenho</strong> com
        otimiza√ß√µes, pois n√£o h√° depend√™ncias. O compilador pode aplicar
        vetoriza√ß√£o SIMD agressiva, mas ser√° limitado pela largura de banda da
        mem√≥ria para escritas.
      </p>

      <h4>üîπ Loop 2 (Soma Acumulativa):</h4>
      <p>
        O ganho com otimiza√ß√£o ser√° <strong>limitado</strong> devido √†
        depend√™ncia sequencial entre as itera√ß√µes. Mesmo com -O3, o compilador
        n√£o pode quebrar completamente a cadeia de depend√™ncias.
      </p>

      <h4>üîπ Loop 3 (Soma com M√∫ltiplas Vari√°veis):</h4>
      <p>
        A quebra de depend√™ncia permite ao compilador aplicar ILP de forma
        efetiva, resultando em <strong>desempenho superior</strong>,
        especialmente com otimiza√ß√µes mais agressivas (-O3).
      </p>
    </div>

    <h2>üß† Conceitos Fundamentais Demonstrados</h2>

    <div class="theory-box">
      <h3>1. üîÑ Depend√™ncia de Dados vs. Paralelismo</h3>
      <p>
        A diferen√ßa entre os loops 2 e 3 ilustra perfeitamente como depend√™ncias
        de dados podem ser gargalo para performance, e como t√©cnicas simples
        (m√∫ltiplos acumuladores) podem quebrar essas depend√™ncias.
      </p>

      <h3>2. üöÄ Poder das Otimiza√ß√µes do Compilador</h3>
      <p>
        A compara√ß√£o entre -O0, -O2 e -O3 demonstra o impacto dram√°tico das
        otimiza√ß√µes autom√°ticas do compilador, especialmente vetoriza√ß√£o SIMD e
        loop unrolling.
      </p>

      <h3>3. ‚öñÔ∏è Trade-offs de Design</h3>
      <p>
        O loop 3 mostra como pequenas mudan√ßas no c√≥digo (usar 4 vari√°veis em
        vez de 1) podem ter impacto dram√°tico na performance, ilustrando a
        import√¢ncia de escrever c√≥digo "amig√°vel ao compilador".
      </p>

      <h3>4. üèóÔ∏è Arquitetura de Processadores Modernos</h3>
      <p>
        Os resultados refletem caracter√≠sticas de CPUs modernas: m√∫ltiplas
        unidades funcionais, pipelines superescalares, e instru√ß√µes SIMD (SSE,
        AVX).
      </p>
    </div>

    <h2>üí° Li√ß√µes Pr√°ticas</h2>

    <div class="highlight">
      <ul>
        <li>
          <strong>Evite depend√™ncias desnecess√°rias:</strong> Use m√∫ltiplos
          acumuladores quando poss√≠vel
        </li>
        <li>
          <strong>Confie no compilador:</strong> Otimiza√ß√µes modernas s√£o muito
          eficazes quando o c√≥digo permite
        </li>
        <li>
          <strong>Profile antes de otimizar:</strong> Me√ßa o impacto real das
          diferentes abordagens
        </li>
        <li>
          <strong>Entenda sua arquitetura:</strong> Diferentes CPUs podem
          apresentar resultados distintos
        </li>
        <li>
          <strong>Loop unrolling:</strong> Pode ser ben√©fico mesmo quando feito
          manualmente
        </li>
      </ul>
    </div>

    <div class="footer">
      <p>
        Programa√ß√£o Paralela - Tarefa 2: An√°lise de Paralelismo ao N√≠vel de
        Instru√ß√£o (ILP)
      </p>
      <p>
        Documento gerado automaticamente - Para convers√£o em PDF use: Ctrl+P ‚Üí
        Salvar como PDF
      </p>
    </div>
  </body>
</html>
