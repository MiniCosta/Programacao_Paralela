# Tarefa 11: Simula√ß√£o de Viscosidade com OpenMP

## üìã Descri√ß√£o do Projeto

Esta implementa√ß√£o simula o movimento de um fluido usando uma vers√£o simplificada da **equa√ß√£o de Navier-Stokes**, considerando apenas os efeitos da viscosidade. O projeto demonstra conceitos de:

- **Simula√ß√£o num√©rica** usando diferen√ßas finitas
- **Paraleliza√ß√£o** com OpenMP
- **An√°lise de performance** de diferentes estrat√©gias de escalonamento
- **Impacto da cl√°usula collapse** na paraleliza√ß√£o de loops aninhados
- **An√°lise de escalabilidade** com PaScal Suite
- **Par√¢metros configur√°veis** para diferentes tamanhos de problema

### Equa√ß√£o Implementada
```
‚àÇu/‚àÇt = ŒΩ‚àá¬≤u
‚àÇv/‚àÇt = ŒΩ‚àá¬≤v
```
Onde:
- `u, v`: componentes da velocidade nas dire√ß√µes x e y
- `ŒΩ`: viscosidade cinem√°tica (0.1)
- `‚àá¬≤`: operador laplaciano (difus√£o)

## üöÄ Compila√ß√£o e Execu√ß√£o

### Compila√ß√£o

#### Compila√ß√£o B√°sica (sem PaScal):
```bash
gcc tarefa11.c -o tarefa11 -fopenmp -lm -O2
```

#### Compila√ß√£o com PaScal Suite:
```bash
gcc -fopenmp -I/home/paulobraga08/pascal-releases-master/include \
    -L/home/paulobraga08/pascal-releases-master/lib \
    tarefa11.c -lmpascalops -lm -o tarefa11
```

### Execu√ß√£o

#### Execu√ß√£o com par√¢metros padr√£o:
```bash
./tarefa11
# Grade: 512x512, Itera√ß√µes: 5000
```

#### Execu√ß√£o com par√¢metros customizados:
```bash
./tarefa11 [tamanho_grade] [num_iteracoes]
```

**Exemplos:**
```bash
./tarefa11 128 500      # Grade 128x128, 500 itera√ß√µes (teste r√°pido)
./tarefa11 256 1000     # Grade 256x256, 1000 itera√ß√µes (m√©dio)
./tarefa11 512 2000     # Grade 512x512, 2000 itera√ß√µes (padr√£o alto)
./tarefa11 1024 3000    # Grade 1024x1024, 3000 itera√ß√µes (intensivo)
```

**Limita√ß√µes:**
- Tamanho da grade: 1 ‚â§ N ‚â§ 2048
- N√∫mero de itera√ß√µes: 1 ‚â§ ITER ‚â§ 50000
- Valores inv√°lidos retornam erro com instru√ß√µes de uso

## üî¨ Par√¢metros da Simula√ß√£o

### Par√¢metros Configur√°veis
| Par√¢metro | Padr√£o | Intervalo | Descri√ß√£o |
|-----------|--------|-----------|-----------|
| **Grade (N)** | 512√ó512 | 1√ó1 a 2048√ó2048 | Resolu√ß√£o espacial |
| **Itera√ß√µes** | 5000 | 1 a 50000 | Passos temporais |

### Par√¢metros Fixos
| Par√¢metro | Valor | Descri√ß√£o |
|-----------|-------|-----------|
| **Viscosidade (ŒΩ)** | 0.1 | Coeficiente de difus√£o |
| **Passo temporal (Œît)** | 0.00001 | Incremento de tempo |
| **Threads** | 4 | N√∫mero de threads paralelas |

### Aloca√ß√£o Din√¢mica de Mem√≥ria
O programa utiliza **aloca√ß√£o din√¢mica** para as matrizes, permitindo:
- **Flexibilidade**: Tamanhos de grade vari√°veis
- **Efici√™ncia**: Uso otimizado da mem√≥ria
- **Escalabilidade**: Teste com diferentes workloads

## üß™ An√°lise com PaScal Suite

### Instrumenta√ß√£o Manual
O c√≥digo inclui **instrumenta√ß√£o manual** com PaScal para an√°lise detalhada:

```c
pascal_start(1);  // Simula√ß√£o completa
pascal_start(2);  // Regi√£o static
pascal_start(3);  // Regi√£o collapse  
pascal_start(4);  // Schedule static
pascal_start(5);  // Schedule dynamic
pascal_start(6);  // Schedule guided
```

### Comando de An√°lise
```bash
# Configurar ambiente Pascal
cd /home/paulobraga08/pascal-releases-master && source env.sh

# An√°lise de escalabilidade completa
pascalanalyzer ./tarefa11 --inst man \
    --cors 1,2,4 \
    --ipts "128 500","256 1000","512 2000" \
    --rpts 2 \
    --outp escalabilidade_variavel.json \
    --verb INFO
```

**Par√¢metros:**
- `--inst man`: Instrumenta√ß√£o manual
- `--cors 1,2,4`: Teste com 1, 2 e 4 cores
- `--ipts`: Diferentes tamanhos de problema  
- `--rpts 2`: 2 repeti√ß√µes por configura√ß√£o
- `--outp`: Arquivo de sa√≠da JSON

## üß™ Testes Realizados

### Execu√ß√£o Autom√°tica
O programa executa automaticamente os seguintes testes:

1. **Simula√ß√£o Serial**: Execu√ß√£o sequencial para baseline
2. **Simula√ß√£o Static**: Paraleliza√ß√£o com `schedule(static)`
3. **Simula√ß√£o Collapse**: Teste do impacto da cl√°usula `collapse(2)`
4. **Compara√ß√£o de Schedules**: Teste de `static`, `dynamic` e `guided`

### Regi√µes Instrumentadas (PaScal)
```
Regi√£o 1: Simula√ß√£o completa (main)
Regi√£o 2: Vers√£o Static
Regi√£o 3: Vers√£o Collapse  
Regi√£o 4: Schedule Static
Regi√£o 5: Schedule Dynamic
Regi√£o 6: Schedule Guided
```

## üìä An√°lise dos Resultados

### Resultados da An√°lise PaScal

Com base na execu√ß√£o do comando:
```bash
pascalanalyzer ./tarefa11 --inst man --cors 1,2,4 --ipts "128 500","256 1000","512 2000" --rpts 2 --outp escalabilidade_variavel.json --verb INFO
```

#### Tempos de Execu√ß√£o Obtidos (em segundos):

| Configura√ß√£o | 1 Core | 2 Cores | 4 Cores | Speedup 4 vs 1 |
|--------------|--------|---------|---------|-----------------|
| **128√ó128, 500 iter** | ~0.70 | ~0.76 | ~0.75 | 0.93√ó (overhead) |
| **256√ó256, 1000 iter** | ~5.25 | ~5.27 | ~5.20 | 1.01√ó (neutro) |
| **512√ó512, 2000 iter** | ~50.88 | ~51.35 | ~50.42 | 1.01√ó (neutro) |

### An√°lise de Escalabilidade

#### üîç **Escalabilidade Forte (Strong Scaling)**
**Problema fixo, mais cores:**

**Observa√ß√µes:**
- **Problemas pequenos (128√ó128)**: Overhead de paraleliza√ß√£o supera benef√≠cios
- **Problemas m√©dios/grandes**: Speedup limitado devido ao algoritmo sequencial dominante
- **Lei de Amdahl**: Partes seriais limitam ganhos de paraleliza√ß√£o

#### üìà **Escalabilidade Fraca (Weak Scaling)**  
**Trabalho proporcional aos cores:**

| Cores | Grade | Tempo/Core | Efici√™ncia |
|-------|-------|------------|------------|
| 1 | 128√ó128 | ~0.70s | 100% |
| 2 | 181√ó181* | ~0.76s | 92% |
| 4 | 256√ó256* | ~0.75s | 93% |

*_Valores aproximados para manter trabalho constante por core_

### Interpreta√ß√£o dos Resultados

#### ‚ö†Ô∏è **Limita√ß√µes Observadas:**

1. **Algoritmo Sequencial Dominante**:
   - Laplaciano de 5 pontos tem depend√™ncias sequenciais
   - Copiar matrizes √© inerentemente sequencial por itera√ß√£o

2. **Overhead de Sincroniza√ß√£o**:
   - Barrier impl√≠cito no final de cada regi√£o paralela
   - Overhead mais significativo que ganhos para problemas pequenos

3. **Padr√£o de Acesso √† Mem√≥ria**:
   - Cache misses aumentam com paraleliza√ß√£o
   - Falsas compartilhamentos entre threads

#### ‚úÖ **Pontos Positivos:**

1. **Implementa√ß√£o Correta**:
   - Resultados consistentes entre repeti√ß√µes
   - Instrumenta√ß√£o Pascal funcionando adequadamente

2. **Escalabilidade de Problema**:
   - Tempos aumentam previsivelmente com tamanho
   - Complexidade O(N¬≤ √ó ITER) confirmada

3. **Flexibilidade**:
   - Sistema configur√°vel para diferentes an√°lises
   - Base s√≥lida para otimiza√ß√µes futuras

### Speedup por Estrat√©gia de Schedule

#### Execu√ß√£o Anterior (Grade 512√ó512, 5000 iter):
```
Serial:   ~34.0s
Static:   ~15.0s ‚Üí Speedup: 2.27√ó
Collapse: ~15.2s ‚Üí Speedup: 2.24√ó  
Dynamic:  ~14.4s ‚Üí Speedup: 2.36√ó
Guided:   ~14.4s ‚Üí Speedup: 2.36√ó
```

**Ranking de Performance:**
1. **Dynamic/Guided** (~2.36√ó) - Melhor balanceamento
2. **Static** (~2.27√ó) - Baixo overhead, mas menos flex√≠vel
3. **Collapse** (~2.24√ó) - Overhead adicional vis√≠vel

### Dados do PaScal Analyzer

#### Estrutura dos Resultados JSON:
```json
"data": {
  "4;0;1": {  // 4 cores, input 0 (128x128), repeti√ß√£o 1
    "regions": {
      "1.2": [start_time, stop_time, start_line, stop_line, thread_id, filename],
      "1.3": [...],  // Diferentes regi√µes instrumentadas
      ...
    }
  }
}
```

#### Mapeamento das Regi√µes:
- **"1"**: Simula√ß√£o completa (main)
- **"1.2"**: Vers√£o Static (regi√£o 2)  
- **"1.3"**: Vers√£o Collapse (regi√£o 3)
- **"1.4"**: Schedule Static (regi√£o 4)
- **"1.5"**: Schedule Dynamic (regi√£o 5)
- **"1.6"**: Schedule Guided (regi√£o 6)

#### Configura√ß√µes Testadas:
- **Input 0**: `128 500` (grade 128√ó128, 500 itera√ß√µes)
- **Input 1**: `256 1000` (grade 256√ó256, 1000 itera√ß√µes)  
- **Input 2**: `512 2000` (grade 512√ó512, 2000 itera√ß√µes)

### Interpreta√ß√£o dos Schedules

#### üîπ **Static (Est√°tica)**
- **Como funciona**: Divis√£o pr√©-definida e igual das itera√ß√µes
- **Vantagens**: Baixo overhead, previs√≠vel
- **Melhor para**: Cargas de trabalho uniformes (como nossa simula√ß√£o)

#### üîπ **Dynamic (Din√¢mica)**  
- **Como funciona**: Distribui√ß√£o sob demanda em blocos fixos
- **Vantagens**: Adapt√°vel a cargas vari√°veis
- **Desvantagem**: Maior overhead para problemas regulares

#### üîπ **Guided (Guiada)**
- **Como funciona**: Blocos de tamanho decrescente
- **Uso**: Equilibrio entre static e dynamic
- **Performance**: Geralmente intermedi√°ria

### üé≠ Analogias para os Schedules

Para entender melhor como cada schedule funciona, imagine uma **f√°brica com 4 trabalhadores** processando **1000 pe√ßas**:

#### üì¶ **Static - "Divis√£o Fixa"**
```
Trabalhador 1: pe√ßas 1-250
Trabalhador 2: pe√ßas 251-500  
Trabalhador 3: pe√ßas 501-750
Trabalhador 4: pe√ßas 751-1000
```
**Analogia**: Como dividir uma pizza em fatias iguais - cada pessoa sabe exatamente qual peda√ßo √© seu desde o in√≠cio.
#### üèÉ **Dynamic - "Fila do Banco"**
```
Fila de tarefas: [chunk1][chunk2][chunk3]...[chunkN]
Trabalhador livre pega pr√≥ximo chunk da fila
```
**Analogia**: Como um caixa de banco - quando um cliente termina, o pr√≥ximo da fila √© atendido. Funciona bem quando alguns clientes demoram mais (itera√ß√µes complexas).

#### üìà **Guided - "Fatias Decrescentes"**
```
1¬∫ chunk: 400 pe√ßas
2¬∫ chunk: 300 pe√ßas  
3¬∫ chunk: 200 pe√ßas
4¬∫ chunk: 100 pe√ßas
```
**Analogia**: Como comer uma torta come√ßando com fatias grandes e diminuindo conforme fica saciado. Combina a efici√™ncia inicial do static com a flexibilidade final do dynamic.

### Cl√°usula Collapse

A diretiva `collapse(2)` combina dois loops aninhados em um √∫nico espa√ßo de itera√ß√£o:

```c
#pragma omp parallel for schedule(static) collapse(2)
for (int i = 1; i < N-1; i++) {
    for (int j = 1; j < N-1; j++) {
        // Computa√ß√£o aqui
    }
}
```

**Benef√≠cios:**
- Aumenta o paralelismo dispon√≠vel
- Melhora balanceamento de carga
- Mais eficiente com muitos threads

**Limita√ß√µes:**
- Pode adicionar overhead para problemas pequenos
- Nem sempre resulta em speedup

## üìà Como Interpretar a Sa√≠da

### Exemplo de Sa√≠da Real:
```
=== SIMULA√á√ÉO DE VISCOSIDADE - NAVIER-STOKES ===
Grade: 512x512, Itera√ß√µes: 5000, Viscosidade: 0.100
N√∫mero de threads: 4

Estado inicial: perturba√ß√£o criada no centro

=== VERS√ÉO 1: SIMULA√á√ÉO SERIAL ===
Tempo VERS√ÉO 1 (serial): 33.7629 segundos

=== VERS√ÉO 2: SIMULA√á√ÉO STATIC (4 threads) ===  
Tempo VERS√ÉO 2 (static): 15.0199 segundos

=== VERS√ÉO 3: SIMULA√á√ÉO COLLAPSE (4 threads) ===
Tempo VERS√ÉO 3 (collapse): 15.2336 segundos

=== VERS√ïES 4-6: COMPARA√á√ÉO DE SCHEDULES ===
=== VERS√ÉO 4: Testando schedule static ===
Tempo VERS√ÉO 4 (static): 15.1564 segundos
=== VERS√ÉO 5: Testando schedule dynamic ===
Tempo VERS√ÉO 5 (dynamic): 14.3926 segundos  
=== VERS√ÉO 6: Testando schedule guided ===
Tempo VERS√ÉO 6 (guided): 14.4305 segundos
```

### An√°lise:
1. **Dynamic** apresenta melhor performance neste caso espec√≠fico
2. **Static** e **Guided** t√™m performance similar
3. **Collapse** adiciona pequeno overhead (~1%)
4. **Speedup** de ~2.35x com 4 threads √© bom para este problema

## üéØ Conceitos Demonstrados

- **Simula√ß√£o de PDE**: Implementa√ß√£o num√©rica de equa√ß√µes diferenciais
- **Stencil Computations**: Padr√£o de acesso a vizinhos em grade
- **OpenMP Scheduling**: Diferentes estrat√©gias de distribui√ß√£o de trabalho
- **Performance Analysis**: Medi√ß√£o e compara√ß√£o de tempos de execu√ß√£o
- **Paraleliza√ß√£o de Loops**: T√©cnicas para acelerar computa√ß√£o intensiva
- **Instrumenta√ß√£o Manual**: Profiling detalhado com PaScal Suite
- **An√°lise de Escalabilidade**: Strong e weak scaling
- **Aloca√ß√£o Din√¢mica**: Gerenciamento flex√≠vel de mem√≥ria
- **Lei de Amdahl**: Limita√ß√µes pr√°ticas da paraleliza√ß√£o

## üî¨ Arquivos Gerados

### Resultados de An√°lise
- `escalabilidade_variavel.json`: Dados completos do PaScal Analyzer
- `teste_manual.json`: Resultados de testes anteriores

### Visualiza√ß√£o
Acesse https://pascalsuite.imd.ufrn.br/pascal-viewer e fa√ßa upload dos arquivos JSON para:
- **Heatmaps de escalabilidade**
- **Gr√°ficos de efici√™ncia paralela**  
- **Compara√ß√£o entre regi√µes**
- **An√°lise hier√°rquica de performance**

## üìö Conclus√µes

### Principais Aprendizados

1. **Nem toda paraleliza√ß√£o resulta em speedup**:
   - Overhead pode superar benef√≠cios para problemas pequenos
   - An√°lise de custo-benef√≠cio √© essencial

2. **Diferentes schedules t√™m comportamentos distintos**:
   - `dynamic`/`guided` melhor para cargas desbalanceadas
   - `static` mais eficiente para cargas uniformes

3. **Escalabilidade depende do problema**:
   - Tamanho m√≠nimo necess√°rio para benef√≠cios
   - Lei de Amdahl limita speedups te√≥ricos

4. **Instrumenta√ß√£o √© fundamental**:
   - PaScal Suite oferece insights detalhados
   - Medi√ß√µes precisas guiam otimiza√ß√µes

### Pr√≥ximos Passos

- **Otimiza√ß√µes de algoritmo**: Reduzir componentes sequenciais
- **Otimiza√ß√µes de mem√≥ria**: Melhorar localidade de cache
- **Paraleliza√ß√£o temporal**: Explorar outras dimens√µes
- **GPU Computing**: Avaliar acelera√ß√£o em GPUs

## üõ†Ô∏è Troubleshooting

### Problemas Comuns

#### Erro de Compila√ß√£o: "undefined reference to pascal_start"
```bash
# Solu√ß√£o: Compilar com biblioteca Pascal
gcc -fopenmp -I/path/to/pascal/include -L/path/to/pascal/lib tarefa11.c -lmpascalops -lm -o tarefa11
```

#### Erro: "Pascal not running"
```bash
# Normal quando executado diretamente (sem pascalanalyzer)
# Para an√°lise completa, use:
pascalanalyzer ./tarefa11 --inst man --cors 1,2,4 --ipts "128 500" --outp resultado.json
```

#### Memoria insuficiente para grades grandes
```bash
# Reduzir tamanho do problema:
./tarefa11 512 1000    # Em vez de 1024 3000
```

### Exemplos de Uso Avan√ßado

#### An√°lise r√°pida (desenvolvimento):
```bash
pascalanalyzer ./tarefa11 --inst man --cors 2,4 --ipts "128 100","256 200" --rpts 1 --outp teste_rapido.json --verb WARNING
```

#### An√°lise completa (produ√ß√£o):
```bash
pascalanalyzer ./tarefa11 --inst man --cors 1,2,4,8 --ipts "128 500","256 1000","512 2000","1024 3000" --rpts 3 --idtm 5 --outp analise_completa.json --verb INFO
```

#### An√°lise espec√≠fica de schedule:
```bash
# Executar apenas uma vez e analisar regi√µes 4-6
./tarefa11 256 1000
# Depois extrair dados das regi√µes no JSON gerado
```
