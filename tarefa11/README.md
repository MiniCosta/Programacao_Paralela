# Tarefa 11: SimulaÃ§Ã£o de Viscosidade com OpenMP

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Esta implementaÃ§Ã£o simula o movimento de um fluido usando uma versÃ£o simplificada da **equaÃ§Ã£o de Navier-Stokes**, considerando apenas os efeitos da viscosidade. O projeto demonstra conceitos de:

- **SimulaÃ§Ã£o numÃ©rica** usando diferenÃ§as finitas
- **ParalelizaÃ§Ã£o** com OpenMP
- **AnÃ¡lise de performance** de diferentes estratÃ©gias de escalonamento
- **Impacto da clÃ¡usula collapse** na paralelizaÃ§Ã£o de loops aninhados

### EquaÃ§Ã£o Implementada
```
âˆ‚u/âˆ‚t = Î½âˆ‡Â²u
âˆ‚v/âˆ‚t = Î½âˆ‡Â²v
```
Onde:
- `u, v`: componentes da velocidade nas direÃ§Ãµes x e y
- `Î½`: viscosidade cinemÃ¡tica (0.1)
- `âˆ‡Â²`: operador laplaciano (difusÃ£o)

## ğŸš€ CompilaÃ§Ã£o e ExecuÃ§Ã£o

### CompilaÃ§Ã£o
```bash
gcc tarefa11.c -o tarefa11 -fopenmp -lm -O2
```

### ExecuÃ§Ã£o

#### ExecuÃ§Ã£o com nÃºmero padrÃ£o de threads (4):
```bash
./tarefa11
```

#### ExecuÃ§Ã£o com nÃºmero especÃ­fico de threads:
```bash
./tarefa11 [nÃºmero_de_threads]
```

**Exemplos:**
```bash
./tarefa11 1    # Executa com 1 thread (forÃ§a serial)
./tarefa11 2    # Executa com 2 threads
./tarefa11 4    # Executa com 4 threads (padrÃ£o)
./tarefa11 8    # Executa com 8 threads
```

**LimitaÃ§Ãµes:**
- NÃºmero de threads deve estar entre 1 e 8
- Valores invÃ¡lidos retornam erro com instruÃ§Ãµes de uso

## ğŸ”¬ ParÃ¢metros da SimulaÃ§Ã£o

| ParÃ¢metro | Valor | DescriÃ§Ã£o |
|-----------|-------|-----------|
| **Grade** | 512x512 | ResoluÃ§Ã£o espacial |
| **IteraÃ§Ãµes** | 5000 | Passos temporais |
| **Viscosidade (Î½)** | 0.1 | Coeficiente de difusÃ£o |
| **Passo temporal (Î”t)** | 0.00001 | Incremento de tempo |

## ğŸ§ª Testes Realizados

O programa executa automaticamente os seguintes testes:

1. **SimulaÃ§Ã£o Serial**: ExecuÃ§Ã£o sequencial para baseline
2. **SimulaÃ§Ã£o Static**: ParalelizaÃ§Ã£o com `schedule(static)`
3. **SimulaÃ§Ã£o Collapse**: Teste do impacto da clÃ¡usula `collapse(2)`
4. **ComparaÃ§Ã£o de Schedules**: Teste de `static`, `dynamic` e `guided`

## ğŸ“Š AnÃ¡lise dos Resultados

### Speedup Calculado
Com base na execuÃ§Ã£o realizada com 4 cores:

```
SimulaÃ§Ã£o Serial:     ~33.8s
Static:   ~15.0s â†’ Speedup: ~2.25x
Collapse: ~15.2s â†’ Speedup: ~2.22x
Dynamic:  ~14.4s â†’ Speedup: ~2.35x
```

### InterpretaÃ§Ã£o dos Schedules

#### ğŸ”¹ **Static (EstÃ¡tica)**
- **Como funciona**: DivisÃ£o prÃ©-definida e igual das iteraÃ§Ãµes
- **Vantagens**: Baixo overhead, previsÃ­vel
- **Melhor para**: Cargas de trabalho uniformes (como nossa simulaÃ§Ã£o)

#### ğŸ”¹ **Dynamic (DinÃ¢mica)**  
- **Como funciona**: DistribuiÃ§Ã£o sob demanda em blocos fixos
- **Vantagens**: AdaptÃ¡vel a cargas variÃ¡veis
- **Desvantagem**: Maior overhead para problemas regulares

#### ğŸ”¹ **Guided (Guiada)**
- **Como funciona**: Blocos de tamanho decrescente
- **Uso**: Equilibrio entre static e dynamic
- **Performance**: Geralmente intermediÃ¡ria

### ğŸ­ Analogias para os Schedules

Para entender melhor como cada schedule funciona, imagine uma **fÃ¡brica com 4 trabalhadores** processando **1000 peÃ§as**:

#### ğŸ“¦ **Static - "DivisÃ£o Fixa"**
```
Trabalhador 1: peÃ§as 1-250
Trabalhador 2: peÃ§as 251-500  
Trabalhador 3: peÃ§as 501-750
Trabalhador 4: peÃ§as 751-1000
```
**Analogia**: Como dividir uma pizza em fatias iguais - cada pessoa sabe exatamente qual pedaÃ§o Ã© seu desde o inÃ­cio.
#### ğŸƒ **Dynamic - "Fila do Banco"**
```
Fila de tarefas: [chunk1][chunk2][chunk3]...[chunkN]
Trabalhador livre pega prÃ³ximo chunk da fila
```
**Analogia**: Como um caixa de banco - quando um cliente termina, o prÃ³ximo da fila Ã© atendido. Funciona bem quando alguns clientes demoram mais (iteraÃ§Ãµes complexas).

#### ğŸ“ˆ **Guided - "Fatias Decrescentes"**
```
1Âº chunk: 400 peÃ§as
2Âº chunk: 300 peÃ§as  
3Âº chunk: 200 peÃ§as
4Âº chunk: 100 peÃ§as
```
**Analogia**: Como comer uma torta comeÃ§ando com fatias grandes e diminuindo conforme fica saciado. Combina a eficiÃªncia inicial do static com a flexibilidade final do dynamic.

### ClÃ¡usula Collapse

A diretiva `collapse(2)` combina dois loops aninhados em um Ãºnico espaÃ§o de iteraÃ§Ã£o:

```c
#pragma omp parallel for schedule(static) collapse(2)
for (int i = 1; i < N-1; i++) {
    for (int j = 1; j < N-1; j++) {
        // ComputaÃ§Ã£o aqui
    }
}
```

**BenefÃ­cios:**
- Aumenta o paralelismo disponÃ­vel
- Melhora balanceamento de carga
- Mais eficiente com muitos threads

**LimitaÃ§Ãµes:**
- Pode adicionar overhead para problemas pequenos
- Nem sempre resulta em speedup

## ğŸ“ˆ Como Interpretar a SaÃ­da

### Exemplo de SaÃ­da Real:
```
=== SIMULAÃ‡ÃƒO DE VISCOSIDADE - NAVIER-STOKES ===
Grade: 512x512, IteraÃ§Ãµes: 5000, Viscosidade: 0.100
NÃºmero de threads: 4

Estado inicial: perturbaÃ§Ã£o criada no centro

=== VERSÃƒO 1: SIMULAÃ‡ÃƒO SERIAL ===
Tempo VERSÃƒO 1 (serial): 33.7629 segundos

=== VERSÃƒO 2: SIMULAÃ‡ÃƒO STATIC (4 threads) ===  
Tempo VERSÃƒO 2 (static): 15.0199 segundos

=== VERSÃƒO 3: SIMULAÃ‡ÃƒO COLLAPSE (4 threads) ===
Tempo VERSÃƒO 3 (collapse): 15.2336 segundos

=== VERSÃ•ES 4-6: COMPARAÃ‡ÃƒO DE SCHEDULES ===
=== VERSÃƒO 4: Testando schedule static ===
Tempo VERSÃƒO 4 (static): 15.1564 segundos
=== VERSÃƒO 5: Testando schedule dynamic ===
Tempo VERSÃƒO 5 (dynamic): 14.3926 segundos  
=== VERSÃƒO 6: Testando schedule guided ===
Tempo VERSÃƒO 6 (guided): 14.4305 segundos
```

### AnÃ¡lise:
1. **Dynamic** apresenta melhor performance neste caso especÃ­fico
2. **Static** e **Guided** tÃªm performance similar
3. **Collapse** adiciona pequeno overhead (~1%)
4. **Speedup** de ~2.35x com 4 threads Ã© bom para este problema

## ğŸ¯ Conceitos Demonstrados

- **SimulaÃ§Ã£o de PDE**: ImplementaÃ§Ã£o numÃ©rica de equaÃ§Ãµes diferenciais
- **Stencil Computations**: PadrÃ£o de acesso a vizinhos em grade
- **OpenMP Scheduling**: Diferentes estratÃ©gias de distribuiÃ§Ã£o de trabalho
- **Performance Analysis**: MediÃ§Ã£o e comparaÃ§Ã£o de tempos de execuÃ§Ã£o
- **ParalelizaÃ§Ã£o de Loops**: TÃ©cnicas para acelerar computaÃ§Ã£o intensiva
